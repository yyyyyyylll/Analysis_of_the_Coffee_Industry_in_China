from DrissionPage import ChromiumPage, ChromiumOptions
import pandas as pd
import os
import re
import time
import random  # å¼•å…¥éšæœºåº“

# ========== å‚æ•°è®¾ç½® ==========

csv_input_file = 'æœªæ¥åæ ‡ç³»-ç‘å¹¸å®˜å·é¦–é¡µæ•°æ®.csv'
csv_output_detail = 'ç‘å¹¸å®˜å·å°çº¢ä¹¦å†…å®¹.csv'
batch_write_size = 5  # é™ä½æ‰¹æ¬¡å¤§å°ï¼Œé˜²æ­¢ä¸­é—´æ–­æ‰æŸå¤±å¤ªå¤šæ•°æ®


# ========== è¯»å–å‡½æ•° ==========
def robust_read_csv(file_path):
    try:
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        print("âœ… ä½¿ç”¨ utf-8-sig æˆåŠŸè¯»å–æ–‡ä»¶")
        return df
    except Exception:
        try:
            df = pd.read_csv(file_path, encoding='gb18030')
            print("âœ… ä½¿ç”¨ gb18030 æˆåŠŸè¯»å–æ–‡ä»¶")
            return df
        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å– CSVï¼š{e}")
            raise e


# ========== å†™å…¥CSV ==========
def write_data_to_csv(data_list, filename):
    if not data_list:
        return
    header = not os.path.exists(filename)
    df = pd.DataFrame(data_list)
    columns_order = ['å¸–å­é“¾æ¥', 'æ ‡é¢˜', 'æ­£æ–‡', 'æ ‡ç­¾', 'ç‚¹èµæ•°', 'æ”¶è—æ•°', 'è¯„è®ºæ•°']
    columns_to_write = [col for col in columns_order if col in df.columns]
    df[columns_to_write].to_csv(filename, mode='a', header=header, index=False, encoding='utf-8-sig')


# ========== åˆå§‹åŒ–æµè§ˆå™¨ ==========
co = ChromiumOptions()
co.set_browser_path(r'C:\Program Files\Google\Chrome\Application\chrome.exe')
dp = ChromiumPage(co)

# è®¾ç½®ä¸€ä¸‹æµè§ˆå™¨çš„User-Agentï¼Œæ¨¡æ‹Ÿå¸¸è§„è®¿é—®ï¼ˆDrissionPageé»˜è®¤å·²å¤„ç†ï¼Œæ˜¾å¼è®¾ç½®æ›´ç¨³å¦¥ï¼‰
# dp.set_user_agent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')

dp.get('https://www.xiaohongshu.com')
input("ğŸš¨ è¯·åœ¨å¼¹å‡ºçš„æµè§ˆå™¨ä¸­æ‰‹åŠ¨å®Œæˆç™»å½•ï¼Œç™»å½•æˆåŠŸååœ¨æ­¤å¤„æŒ‰ã€å›è½¦ã€‘ç»§ç»­...")

# ========== è¯»å–é“¾æ¥ ==========
try:
    df_links = robust_read_csv(csv_input_file)
    if 'å¸–å­é“¾æ¥' not in df_links.columns:
        raise ValueError("âŒ CSV æ–‡ä»¶ä¸­æœªæ‰¾åˆ° 'å¸–å­é“¾æ¥' åˆ—")
    detail_links = df_links['å¸–å­é“¾æ¥'].dropna().unique().tolist()
    print(f"ğŸ“Š æˆåŠŸè¯»å– {len(detail_links)} æ¡è¯¦æƒ…é“¾æ¥")
except Exception as e:
    print(f"âŒ æ— æ³•è¯»å–è¾“å…¥æ–‡ä»¶ï¼š{e}")
    exit(1)

# ========== æŠ“å–ä¸»å¾ªç¯ ==========
detail_results = []

print("\nğŸš€ å¼€å§‹æŠ“å– (å®‰å…¨æ¨¡å¼ï¼šå·²å¼€å¯éšæœºé•¿å»¶æ—¶)...\n")

for i, url in enumerate(detail_links):
    try:
        dp.get(url)

        # [æ–°å¢] æ¨¡æ‹Ÿé¡µé¢åŠ è½½åçš„â€œäººå·¥é˜…è¯»â€åœé¡¿ (2åˆ°5ç§’éšæœº)
        read_delay = random.uniform(1, 4)
        print(f"   ...æ­£åœ¨æ¨¡æ‹Ÿé˜…è¯»ç­‰å¾… {read_delay:.1f} ç§’")
        time.sleep(read_delay)

        # [ä¿®æ”¹] è¶…æ—¶æ—¶é—´ä» 10 å¢åŠ åˆ° 30ï¼Œé˜²æ­¢ç½‘ç»œæ…¢è¢«è¯¯åˆ¤
        dp.wait.ele_displayed('css:#detail-title', timeout=30)

        # 1. æŠ“å–æ ‡é¢˜
        title_ele = dp.ele('css:#detail-title')
        title = title_ele.text.strip() if title_ele else 'æ— æ ‡é¢˜'

        # 2. æŠ“å–æ­£æ–‡ä¸æ ‡ç­¾
        content_element = dp.ele('css:#desc, .desc')
        content = ''
        tags_str = ''

        if content_element:
            full_text = content_element.text
            hashtags = re.findall(r'#\w+', full_text)
            if hashtags:
                tags_str = ', '.join([tag.lstrip('#') for tag in hashtags])
                content = full_text
                for tag in hashtags:
                    content = content.replace(tag, '')
                content = content.strip()
            else:
                content = full_text.strip()

        if not tags_str:
            tag_eles = dp.eles('css:a#hash-tag')
            if tag_eles:
                tags_str = ', '.join([t.text.strip().lstrip('#') for t in tag_eles])

        # 3. æŠ“å–äº’åŠ¨æ•°æ®
        like_span = dp.ele('css:.engage-bar-container .like-wrapper .count')
        like_count = like_span.text.strip() if like_span else '0'

        collect_span = dp.ele('css:.engage-bar-container .collect-wrapper .count')
        collect_count = collect_span.text.strip() if collect_span else '0'

        comment_span = dp.ele('css:.engage-bar-container .chat-wrapper .count')
        comment_count = comment_span.text.strip() if comment_span else '0'
        if comment_count in ['æŠ¢é¦–è¯„', 'è¯„è®º']:
            comment_count = '0'

        # 4. å­˜å…¥åˆ—è¡¨
        detail_results.append({
            'å¸–å­é“¾æ¥': url,
            'æ ‡é¢˜': title,
            'æ­£æ–‡': content,
            'æ ‡ç­¾': tags_str,
            'ç‚¹èµæ•°': like_count,
            'æ”¶è—æ•°': collect_count,
            'è¯„è®ºæ•°': comment_count
        })

        print(f"âœ” [{i + 1}/{len(detail_links)}] æŠ“å–æˆåŠŸï¼š{title[:15]}...")

    except Exception as e:
        print(f"âŒ [{i + 1}/{len(detail_links)}] æŠ“å–å¤±è´¥ï¼š{url}ï¼ŒåŸå› ï¼š{e}")

    # ========== æ‰¹é‡å†™å…¥ ==========
    if (i + 1) % batch_write_size == 0 or (i + 1) == len(detail_links):
        print(f"ğŸ’¾ æ­£åœ¨å†™å…¥ {len(detail_results)} æ¡æ•°æ®åˆ° CSV...")
        write_data_to_csv(detail_results, csv_output_detail)
        detail_results.clear()

    # [æ–°å¢] æ¯ä¸€è½®ç»“æŸåçš„â€œéšæœºé•¿é—´éš”â€ (6åˆ°12ç§’éšæœº)
    # è¿™æ˜¯åŸæ¥çš„3å€ä»¥ä¸Šï¼ˆåŸä»£ç å‡ ä¹æ— é—´éš”ï¼‰
    # å¦‚æœè¿˜éœ€è¦æ›´æ…¢ï¼Œå¯ä»¥ä¿®æ”¹è¿™é‡Œçš„æ•°å­—ï¼Œä¾‹å¦‚ (10, 20)
    sleep_time = random.uniform(0.5, 2)
    print(f"ğŸ’¤ ä¼‘æ¯ {sleep_time:.1f} ç§’ï¼Œå‡†å¤‡ä¸‹ä¸€æ¡...")
    time.sleep(sleep_time)

print(f"\nğŸ‰ å…¨éƒ¨ä»»åŠ¡å®Œæˆã€‚æ•°æ®å·²ä¿å­˜è‡³ï¼š{csv_output_detail}")