import pandas as pd
import jieba
import collections
import re
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import platform
import os

# ================= é…ç½®åŒºåŸŸ =================
INPUT_FILE = 'ç‘å¹¸æ¶ˆè´¹é™çº§æ•°æ®.csv'
OUTPUT_CSV = 'ç‘å¹¸_è¯é¢‘ç»Ÿè®¡_åŒ…å«ä»·æ ¼.csv'
OUTPUT_IMG = 'ç‘å¹¸_è¯äº‘_åŒ…å«ä»·æ ¼.png'

# 1. ã€è‡ªå®šä¹‰è¯å…¸ã€‘ï¼šå¼ºåˆ¶ jieba ä¸åˆ‡å¼€è¿™äº›è¯
# ä½ å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ä»»ä½•ä½ ä¸æƒ³è¢«åˆ‡å¼€çš„ä¸“æœ‰åè¯
CUSTOM_DICT = [
    '9.9', '9.9å…ƒ', '9å—9', 'ä¹å—ä¹',
    'é…±é¦™æ‹¿é“', 'ç”Ÿæ¤°æ‹¿é“', 'é©¬æ–¯å¡å½­', 'ä¸ç»’æ‹¿é“', 'å°è“æ¯',
    'ç‘å¹¸', 'luckin', 'å’–å•¡', 'ç‹ ç‹ ', 'å†²å†²å†²','å¡çš®å·´æ‹‰','é¬¼ç­ä¹‹åˆƒ','ç–¯ç‹‚åŠ¨ç‰©åŸ'
]

# 2. ã€åŒä¹‰è¯æ˜ å°„ã€‘ï¼šæŠŠä¸åŒçš„å«æ³•ç»Ÿä¸€æˆä¸€ä¸ªæ ‡å‡†è¯
# æ ¼å¼ï¼š'åŸè¯': 'æ ‡å‡†è¯'
SYNONYM_DICT = {

}

# 3. ã€åœç”¨è¯ã€‘ï¼šè¿‡æ»¤æ‰æ— æ„ä¹‰çš„è¯
STOP_WORDS = {
    'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'å»',
    'ä½ ',
    'å§', 'å•Š', 'å—', 'å‘¢', 'å“ˆ', 'é‚£', 'è¿™', 'å¯¹', 'è·Ÿ', 'è¢«', 'ä¸º', 'ä¹‹', 'ä¸', 'åŠ', 'ç­‰', 'æˆ–', 'å¯ä»¥', 'è¿™ä¸ª',
    'é‚£ä¸ª',
    'å› ä¸º', 'æ‰€ä»¥', 'ä½†æ˜¯', 'å¦‚æœ', 'å°±æ˜¯', 'æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬', 'å®ƒä»¬', 'è‡ªå·±', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'è¿™é‡Œ', 'é‚£é‡Œ',
    'ç¬”è®°', 'å°çº¢ä¹¦', 'å…¨æ–‡', 'é“¾æ¥', 'ç½‘é¡µ', 'æŸ¥çœ‹', 'å¤åˆ¶', 'æ‰“å¼€', 'è¯¦æƒ…', 'æ— æ ‡é¢˜', 'å±•å¼€', 'å‘å¸ƒ', 'æ—¶é—´','æ²¡æœ‰','ä¸€æ¯','ä»Šå¤©','æ¯å­','è¿˜æ˜¯','ä¸æ˜¯','ç›´æ¥','ç°åœ¨','æ„Ÿè§‰','ä¸€ä¸‹','ç„¶å','ä¸èƒ½','æ¯”è¾ƒ','ä¸€å¤©','çœŸçš„','å‘˜å·¥','å·¥äºº','å–å’–å•¡','å·¥äºº','æ—¶å€™','å¼€å§‹'
}
# æƒ…ç»ªç»æµæ–°åŠ çš„ï¼š
# ================= åˆå§‹åŒ– Jieba =================
# å°†è‡ªå®šä¹‰è¯åŠ å…¥è¯åº“
for word in CUSTOM_DICT:
    jieba.add_word(word)


# ================= å­—ä½“è®¾ç½® =================
def get_font_path():
    system = platform.system()
    if system == 'Darwin':
        # Mac å­—ä½“å¯»æ‰¾é€»è¾‘
        font_candidates = [
            '/System/Library/Fonts/PingFang.ttc',
            '/System/Library/Fonts/Supplemental/Arial Unicode MS.ttf',
            '/System/Library/Fonts/STHeiti Light.ttc',
        ]
        for font in font_candidates:
            if os.path.exists(font): return font
        return 'Arial'
    elif system == 'Windows':
        return 'C:/Windows/Fonts/simhei.ttf'
    else:
        return None


# ================= è¯»å–æ•°æ® =================
def load_data(filepath):
    try:
        df = pd.read_csv(filepath, encoding='utf-8-sig')
    except:
        try:
            df = pd.read_csv(filepath, encoding='gb18030')
        except Exception as e:
            print(f"âŒ è¯»å–å¤±è´¥: {e}")
            return None
    return df


# ================= æ ¸å¿ƒï¼šæ–‡æœ¬å¤„ç†ä¸åˆ†è¯ =================
def process_text(df):
    print("âœ‚ï¸ æ­£åœ¨è¿›è¡Œæ™ºèƒ½åˆ†è¯å¤„ç†...")
    all_words = []

    # æ‹¼æ¥æ¯ä¸€è¡Œçš„å†…å®¹
    for _, row in df.iterrows():
        title = str(row['æ ‡é¢˜']) if pd.notna(row['æ ‡é¢˜']) else ''
        content = str(row['æ­£æ–‡']) if pd.notna(row['æ­£æ–‡']) else ''
        tags = str(row['æ ‡ç­¾']) if pd.notna(row['æ ‡ç­¾']) else ''

        full_text = f"{title} {content} {tags}"

        # --- ä¿®æ”¹ç‚¹ 1: æ­£åˆ™æ¸…æ´—æ”¾å®½ ---
        # åŸæ¥æ˜¯ r'[^\w\s\u4e00-\u9fa5]' ä¼šæŠŠå°æ•°ç‚¹å’Œæ•°å­—è¿‡æ»¤æ‰
        # ç°åœ¨æ”¹ä¸º r'[^\w\s\u4e00-\u9fa5\.]' å…è®¸å°æ•°ç‚¹ï¼Œä¸”ä¸æ¸…æ´—æ•°å­—
        full_text = re.sub(r'[^\w\s\u4e00-\u9fa5\.]', ' ', full_text)

        # Jieba åˆ†è¯
        words = jieba.lcut(full_text)

        for word in words:
            word = word.strip()

            # è¿‡æ»¤æ‰é•¿åº¦ä¸º1çš„è¯ï¼Œä½†ä¿ç•™ç‰¹æ®Šçš„å•ä¸ªå­—ï¼ˆå¦‚æœæœ‰éœ€è¦ï¼‰
            if len(word) < 2:
                continue

            # --- ä¿®æ”¹ç‚¹ 2: åŒä¹‰è¯æ›¿æ¢ ---
            if word in SYNONYM_DICT:
                word = SYNONYM_DICT[word]

            # --- ä¿®æ”¹ç‚¹ 3: æ™ºèƒ½è¿‡æ»¤é€»è¾‘ ---
            # å¦‚æœåœ¨åœç”¨è¯è¡¨ä¸­ï¼Œè·³è¿‡
            if word in STOP_WORDS:
                continue

            # å¦‚æœæ˜¯çº¯æ•°å­—ï¼ˆå¦‚ 2023, 12ï¼‰ï¼Œé€šå¸¸æ˜¯æ—¥æœŸæˆ–æ— æ„ä¹‰æ•°å­—ï¼Œè·³è¿‡
            # ä½†æ˜¯ï¼å¦‚æœå®ƒåœ¨æˆ‘ä»¬å®šä¹‰çš„â€œä¿ç•™åå•â€é‡Œï¼ˆæ¯”å¦‚ 9.9 è™½ç„¶åƒæ•°å­—ï¼Œä½†æˆ‘ä»¬å·²ç»æ›¿æ¢æˆäº† 9.9å…ƒï¼‰ï¼Œæˆ–è€…å°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„æ ¼å¼
            # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šå¦‚æœæ˜¯çº¯æ•°å­—ä¸”ä¸åœ¨è‡ªå®šä¹‰è¯å…¸é‡Œï¼Œå°±è¿‡æ»¤ã€‚
            # ä½†å› ä¸ºæˆ‘ä»¬æŠŠ '9.9' æ˜ å°„æˆäº† '9.9å…ƒ'ï¼Œå®ƒå°±ä¸å†æ˜¯çº¯æ•°å­—äº†ï¼Œä¼šè¢«ä¿ç•™ã€‚
            if word.replace('.', '').isdigit() and word not in CUSTOM_DICT:
                continue

            all_words.append(word)

    return all_words


# ================= å¯è§†åŒ– =================
def visualize(word_counts):
    font_path = get_font_path()

    # è¯äº‘
    print("â˜ï¸ ç”Ÿæˆè¯äº‘...")
    wc = WordCloud(
        font_path=font_path,
        width=1000, height=800,
        background_color='white',
        max_words=150,
        colormap='tab10'  # æ¢ä¸ªé¢œè‰²é£æ ¼
    )
    wc.generate_from_frequencies(word_counts)
    wc.to_file(OUTPUT_IMG)
    print(f"   å·²ä¿å­˜: {OUTPUT_IMG}")

    # æŸ±çŠ¶å›¾
    print("ğŸ“Š ç”ŸæˆæŸ±çŠ¶å›¾...")
    top_20 = word_counts.most_common(20)
    words = [x[0] for x in top_20]
    counts = [x[1] for x in top_20]

    if platform.system() == 'Darwin':
        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang SC']
    else:
        plt.rcParams['font.sans-serif'] = ['SimHei']
    plt.rcParams['axes.unicode_minus'] = False

    plt.figure(figsize=(12, 6))
    plt.bar(words, counts, color='#ff7f0e')  # æ©™è‰²ç³»ï¼Œåƒç‘å¹¸
    plt.title('Top 20 é«˜é¢‘è¯ ', fontsize=15)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()


# ================= ä¸»ç¨‹åº =================
if __name__ == '__main__':
    if not os.path.exists(INPUT_FILE):
        print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        exit()

    df = load_data(INPUT_FILE)
    if df is not None:
        clean_words = process_text(df)

        # ç»Ÿè®¡
        counter = collections.Counter(clean_words)
        print(f"âœ… ç»Ÿè®¡å®Œæˆï¼Œå…± {len(counter)} ä¸ªç‹¬ç«‹è¯æ±‡")

        # æ‰“å°å‰10ä¸ªçœ‹çœ‹æ•ˆæœ
        print("å‰10é«˜é¢‘è¯:", counter.most_common(10))

        # ä¿å­˜
        pd.DataFrame(counter.most_common(), columns=['è¯æ±‡', 'é¢‘æ¬¡']).to_csv(OUTPUT_CSV, index=False,
                                                                             encoding='utf-8-sig')

        # ç”»å›¾
        visualize(counter)