import pandas as pd
import jieba
import collections
import re
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import platform
import os

# ================= é…ç½®åŒºåŸŸ =================
# è¾“å…¥æ–‡ä»¶ (å¯¹åº”ä½ åˆšæ‰çˆ¬å–çš„ç»“æœ)
INPUT_FILE = 'ç‘å¹¸å®˜å·å°çº¢ä¹¦å†…å®¹_æ ‡å‡†åŒ–è¾“å‡º.csv'
# è¾“å‡ºè¯é¢‘ç»Ÿè®¡è¡¨æ ¼
OUTPUT_CSV = 'ç‘å¹¸_è¯é¢‘ç»Ÿè®¡ç»“æœ.csv'
# è¯äº‘å›¾ä¿å­˜è·¯å¾„
OUTPUT_IMG = 'ç‘å¹¸_è¯äº‘å›¾.png'

# åœç”¨è¯åˆ—è¡¨ (ä¸æƒ³ç»Ÿè®¡çš„æ— æ„ä¹‰è¯æ±‡)
STOP_WORDS = {
    'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'å»',
    'ä½ ',
    'å§', 'å•Š', 'å—', 'å‘¢', 'å“ˆ', 'é‚£', 'è¿™', 'å¯¹', 'è·Ÿ', 'è¢«', 'ä¸º', 'ä¹‹', 'ä¸', 'åŠ', 'ç­‰', 'æˆ–', 'å¯ä»¥', 'è¿™ä¸ª',
    'é‚£ä¸ª',
    'å› ä¸º', 'æ‰€ä»¥', 'ä½†æ˜¯', 'å¦‚æœ', 'å°±æ˜¯', 'æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬', 'å®ƒä»¬', 'è‡ªå·±', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'è¿™é‡Œ', 'é‚£é‡Œ',
    'ç¬”è®°', 'å°çº¢ä¹¦', 'å…¨æ–‡', 'é“¾æ¥', 'ç½‘é¡µ', 'æŸ¥çœ‹', 'å¤åˆ¶', 'æ‰“å¼€', 'è¯¦æƒ…', 'æ— æ ‡é¢˜', 'å±•å¼€','è¿˜æœ‰','è½»è½»','ä»Šå¤©','è¿™æ¯','ä»Šæ—¥','çœŸçš„','èµ·æ¥','è¿™ä¹ˆ','å³å¯','è®°å¾—','æ²¡æœ‰'
}
#


# ================= å­—ä½“è®¾ç½® (è§£å†³ä¸­æ–‡ä¹±ç ) =================
def get_font_path():
    import os
    system = platform.system()

    if system == 'Darwin':  # macOS ç³»ç»Ÿ
        # å®šä¹‰ä¸€ä¸ªå­—ä½“â€œå€™é€‰åå•â€ï¼Œç¨‹åºä¼šä»ä¸Šå¾€ä¸‹æ‰¾ï¼Œæ‰¾åˆ°å“ªä¸ªç”¨å“ªä¸ª
        font_candidates = [
            '/System/Library/Fonts/PingFang.ttc',  # ç°ä»£ macOS é»˜è®¤ä¸­æ–‡å­—ä½“ (è‹¹æ–¹)
            '/System/Library/Fonts/STHeiti Light.ttc',  # è¾ƒæ—§ macOS çš„é€šç”¨å­—ä½“ (åæ–‡é»‘ä½“)
            '/System/Library/Fonts/STHeiti Medium.ttc',
            '/System/Library/Fonts/Supplemental/Arial Unicode MS.ttf',  # æ—§ä»£ç ç”¨çš„è·¯å¾„
            '/Library/Fonts/Arial Unicode.ttf',
        ]

        for font in font_candidates:
            if os.path.exists(font):
                print(f"âœ… å·²å®šä½åˆ°ä¸­æ–‡å­—ä½“: {font}")
                return font

        print("âš ï¸ è­¦å‘Š: æœªåœ¨å¸¸è§è·¯å¾„æ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œè¯äº‘å›¾ä¸­æ–‡å¯èƒ½ä¼šä¹±ç ")
        return 'Arial'  # æœ€åçš„ä¿åº•ï¼Œä½†ä¸æ”¯æŒä¸­æ–‡

    elif system == 'Windows':
        # Windows é€»è¾‘ä¿æŒä¸å˜
        paths = [
            'C:/Windows/Fonts/simhei.ttf',  # é»‘ä½“
            'C:/Windows/Fonts/msyh.ttf',  # å¾®è½¯é›…é»‘
        ]
        for font in paths:
            if os.path.exists(font):
                return font
        return 'Arial'

    else:
        return None  # Linux


# ================= 1. è¯»å–æ•°æ® =================
def load_data(filepath):
    try:
        df = pd.read_csv(filepath, encoding='utf-8-sig')
    except:
        try:
            df = pd.read_csv(filepath, encoding='gb18030')
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return None
    print(f"âœ… æˆåŠŸè¯»å– {len(df)} æ¡æ•°æ®")
    return df


# ================= 2. æ–‡æœ¬æ¸…æ´—ä¸åˆ†è¯ =================
def process_text(df):
    print("âœ‚ï¸ æ­£åœ¨è¿›è¡Œæ–‡æœ¬æ¸…æ´—ä¸åˆ†è¯...")
    text_content = ''

    # æ‹¼æ¥ æ ‡é¢˜ + æ­£æ–‡ + æ ‡ç­¾
    for _, row in df.iterrows():
        # å°†ç©ºå€¼è½¬ä¸ºç©ºå­—ç¬¦ä¸²
        title = str(row['æ ‡é¢˜']) if pd.notna(row['æ ‡é¢˜']) else ''
        content = str(row['æ­£æ–‡']) if pd.notna(row['æ­£æ–‡']) else ''
        tags = str(row['æ ‡ç­¾']) if pd.notna(row['æ ‡ç­¾']) else ''

        # ç®€å•æ¸…æ´—ï¼šå»é™¤ç‰¹æ®Šç¬¦å·ï¼Œåªä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—
        combined = f"{title} {content} {tags}"
        combined = re.sub(r'[^\w\s\u4e00-\u9fa5]', '', combined)
        text_content += combined

    # jieba åˆ†è¯
    words = jieba.lcut(text_content)

    # è¿‡æ»¤åœç”¨è¯ã€å•ä¸ªå­—çš„è¯ï¼ˆé€šå¸¸æ— æ„ä¹‰ï¼‰ã€ç©ºç™½ç¬¦
    clean_words = []
    for word in words:
        word = word.strip()
        if len(word) > 1 and word not in STOP_WORDS and not word.isnumeric():
            clean_words.append(word)

    return clean_words


# ================= 3. ç”Ÿæˆå›¾è¡¨ =================
def visualize(word_counts):
    font_path = get_font_path()

    # --- A. ç”Ÿæˆè¯äº‘å›¾ ---
    print("â˜ï¸ æ­£åœ¨ç”Ÿæˆè¯äº‘å›¾...")
    wc = WordCloud(
        font_path=font_path,
        width=1000, height=800,
        background_color='white',
        max_words=75,
        colormap='viridis'  # é¢œè‰²é£æ ¼
    )
    wc.generate_from_frequencies(word_counts)
    wc.to_file(OUTPUT_IMG)
    print(f"   å·²ä¿å­˜è¯äº‘å›¾: {OUTPUT_IMG}")

    # --- B. ç”ŸæˆæŸ±çŠ¶å›¾ (å‰20ä¸ªé«˜é¢‘è¯) ---
    print("ğŸ“Š æ­£åœ¨ç”ŸæˆæŸ±çŠ¶å›¾...")
    top_20 = word_counts.most_common(20)
    words = [x[0] for x in top_20]
    counts = [x[1] for x in top_20]

    # è®¾ç½® matplotlib å­—ä½“
    if platform.system() == 'Darwin':
        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
    else:
        plt.rcParams['font.sans-serif'] = ['SimHei']
    plt.rcParams['axes.unicode_minus'] = False

    plt.figure(figsize=(12, 6))
    plt.bar(words, counts, color='skyblue')
    plt.title('Top 20 é«˜é¢‘è¯ç»Ÿè®¡', fontsize=15)
    plt.xlabel('è¯æ±‡')
    plt.ylabel('å‡ºç°é¢‘æ¬¡')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()  # å¦‚æœåœ¨ Jupyter é‡Œè¿è¡Œä¼šç›´æ¥æ˜¾ç¤ºï¼Œè„šæœ¬è¿è¡Œä¼šå¼¹çª—


# ================= ä¸»ç¨‹åº =================
if __name__ == '__main__':
    # 1. è¯»å–
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {INPUT_FILE}ï¼Œè¯·ç¡®è®¤æ–‡ä»¶åæ˜¯å¦æ­£ç¡®ã€‚")
        exit()

    df = load_data(INPUT_FILE)

    if df is not None:
        # 2. å¤„ç†
        words = process_text(df)

        # 3. ç»Ÿè®¡
        word_counts = collections.Counter(words)
        print(f"âœ… ç»Ÿè®¡å®Œæˆï¼Œå…±æå–åˆ° {len(word_counts)} ä¸ªä¸åŒçš„è¯æ±‡ã€‚")

        # 4. å¯¼å‡º CSV
        result_df = pd.DataFrame(word_counts.most_common(), columns=['è¯æ±‡', 'é¢‘æ¬¡'])
        result_df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ è¯¦ç»†è¯é¢‘æ•°æ®å·²ä¿å­˜è‡³: {OUTPUT_CSV}")

        # 5. å¯è§†åŒ–
        visualize(word_counts)
        print("\nğŸ‰ åˆ†æå…¨éƒ¨å®Œæˆï¼")